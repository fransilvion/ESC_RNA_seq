---
title: "Machine learning for drugs"
author: "German Novakovskiy"
date: "September 1, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
library(knitr)
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(GEOquery)))
suppressWarnings(suppressMessages(library(data.table)))
suppressWarnings(suppressMessages(library(reshape2)))
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(ggplot2)))
suppressWarnings(suppressMessages(library(cowplot)))
suppressWarnings(suppressMessages(library(limma)))
suppressWarnings(suppressMessages(library(tibble)))
suppressWarnings(suppressMessages(library(RColorBrewer)))
suppressWarnings(suppressMessages(library(edgeR)))
suppressWarnings(suppressMessages(library(readxl)))
suppressWarnings(suppressMessages(library(VennDiagram)))
suppressMessages(suppressWarnings(library(ermineR)))
suppressMessages(suppressWarnings(library(hgu133a.db)))
suppressMessages(suppressWarnings(library(ReactomePA)))
suppressMessages(suppressWarnings(library(clusterProfiler)))
suppressMessages(suppressWarnings(library(fgsea)))
suppressMessages(suppressWarnings(library(stringr)))
suppressMessages(suppressWarnings(library(rlist)))
suppressMessages(suppressWarnings(library(rcdk)))
suppressMessages(suppressWarnings(library(webchem)))
suppressMessages(suppressWarnings(library(caret)))
suppressMessages(suppressWarnings(library(pROC)))
suppressMessages(suppressWarnings(library(glmnet)))
suppressMessages(suppressWarnings(library(ROCR)))
```

Let's build several machine learning models for SOX17 activation prediction based on small molecule chemical structure. We will consider this problem as a binary classification: 0 if SOX17 is not activated, 1 otherwise. Activation of SOX17 will be based on corresponding log fold change from LINCS expression data. 

SOX17 is a major marker of definitive endoderm, it's highly expressed at this stage and it's expression is downregulated during pluripotency stage. 

This is how distribution of SOX17 expression looks like:
```{r}
load("MCF7_gene_expression.Rdata")

sox17_lfc <- rows_cols_gene_expression_mcf7["SOX17",]
#for testing
foxa2_lfc <- rows_cols_gene_expression_mcf7["FOXA2",]
rm(rows_cols_gene_expression_mcf7)

hist(sox17_lfc, breaks=50, main = "SOX17 logFC distribution",
     xlab = "logFC", col = "cyan")
```

Looks like a standard npormal distribution (it should be we log fold changes). We will take 5% (95% percentile) at the right tail as activated genes:
```{r}
#what is 95% percentile
threshold <- quantile(sox17_lfc, c(.95))
threshold
```

Expression of SOX17 in interesting drugs from KEGG/Wiki analysis: 
```{r}
drugs <- c("taxifolin", "SA-1462738", "SA-1938111", "SA-1938219", "SA-247654", "SA-418993", "SA-85901", "SA-89705", "SA-1459008", "BRD-K20168484", "carbetocin", "linifanib", "mestanolone")

sox17_lfc[drugs][sox17_lfc[drugs] > threshold]
```

Only 5 out of 13 molecules!

The same for FOXA2:
```{r}
foxa2_lfc[drugs][foxa2_lfc[drugs] > quantile(foxa2_lfc, c(.95))] #1.007819 
rm(foxa2_lfc)
```
Only 3 molecules are common between these two sets -> SA-1938111, SA-247654, mestanolone

```{r}
#drugs that activate expression of SOX17 
drugs_positive <- sox17_lfc[sox17_lfc >= threshold] #532 drugs

#drugs that do not activate expression of SOX17 (we do not care about inactivation)
drugs_negative <- sox17_lfc[sox17_lfc < threshold] #10095 drugs
```

We will use MACCS small molecule descriptors - binary in nature and typically encode the presence or absence of substructural fragments (calculate them with Rcpi package). 
```{r}
#function for retrieving canonical SMILES from PubChem
#input - drug name
#output - SMILES
getSmiles <- function(drug_name, df_drugs){
  my_drug <- df_drugs %>% filter(pert_iname == drug_name)
  
  #if someone is not 666
  if (nrow(my_drug) > 1){ 
    if (my_drug %>% filter(pubchem_cid != -666) %>% nrow() == 1){
      my_drug <- my_drug %>% filter(pubchem_cid != -666) 
    }
    else if (my_drug %>% filter(is_touchstone != 0) %>% nrow() == 1){
      #if both 666 take with is_touchstone 1
      my_drug <- my_drug %>% filter(is_touchstone != 0)
    } else {
      #like in case of CHIR-99021
      my_drug <- my_drug[1,]
    }
    }
  
  res <- as.character(my_drug$canonical_smiles)
  if (res == -666 | res == 'restricted') { res <- NULL}
  return(res)
}

#function for retrieving MACCS 166 bit descriptors
#input - SMILES
#output - MACCS 166 descriptors
getMACCS <- function(smiles_character){
  mols <- parse.smiles(smiles_character)
  fp <- get.fingerprint(mols[[1]], type="maccs")
  
  #fp is a S4 class, bits field is a vector, indicating the bit positions that are on.
  res <- fp@bits
  return(res)
}
```

Load LINCS drug information (from GSE92742_Broad_LINCS_pert_info.txt.gz)
```{r}
#cols - "pert_id", "pert_iname", "pert_type", "is_touchstone", "inchi_key_prefix", "inchi_key", "canonical_smiles","pubchem_cid" 
drug_info <- read.table("LINCS_compounds_info.txt", header = T, quote = "", sep = "\t", comment.char = "")
dim(drug_info)
```
Note that there are repeats, for example "trichostatin-a" has 2 entries. In this case we take only those, for which pubchem_cid does not equal -666. (however, the one line for this drug with -666 has classical smiles, while another one with pubchem id has isomeric smiles...).
```{r}
#how many drugs among positives have repeats in drug_info file
x <- drug_info %>% filter(pert_iname %in% names(drugs_positive)) 
length(x$pert_iname[which(duplicated(x$pert_iname))])
```
```{r}
#those replicates
as.character(x$pert_iname[which(duplicated(x$pert_iname))])
```
```{r}
#how many drugs among negatives have repeats in drug_info file
x <- drug_info %>% filter(pert_iname %in% names(drugs_negative)) 
length(x$pert_iname[which(duplicated(x$pert_iname))])
```

Note that some of the drugs in info file don't have Smiles. We simply delete them. 

Try to run for some drugs and measure time:
```{r}
#takes ~5 seconds
for_testing <- names(drugs_positive)
start.time <- Sys.time()

drugs_smiles_positive <- sapply(for_testing, getSmiles, drug_info)

#delete zeros if there are some
x <- lapply(drugs_smiles_positive, length)
deleted_positives <- sum(x == 0)
drugs_smiles_positive <- drugs_smiles_positive[which(x != 0)]
###############################

drug_maccs_positive <- sapply(drugs_smiles_positive, getMACCS)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```
```{r}
#takes ~1 minute
for_testing <- names(drugs_negative)
start.time <- Sys.time()
 
drugs_smiles_negative <- sapply(for_testing, getSmiles, drug_info)

#delete zeros if there are some
x <- lapply(drugs_smiles_negative, length)
deleted_negatives <- sum(x == 0)
drugs_smiles_negative <- drugs_smiles_negative[-which(x == 0)]
###############################

drug_maccs_negative <- sapply(drugs_smiles_negative, getMACCS)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```
```{r}
length(drug_maccs_positive)
```
```{r}
length(drug_maccs_negative)
```
```{r}
#function for turning the maccs bit descriptors to binary vector with 166 terms
bitsToVector <- function(non_zero_indexes){
  y <- rep(0, 166)
  y[non_zero_indexes] = 1
  return(y)
}

drug_maccs_positive <- lapply(drug_maccs_positive, bitsToVector)

drug_maccs_negative <- lapply(drug_maccs_negative, bitsToVector)

#converting lists to data frame
drugs <- names(drug_maccs_positive)
drug_maccs_positive <- data.frame(matrix(unlist(drug_maccs_positive), nrow=532, byrow=T))
rownames(drug_maccs_positive) <- drugs

drugs <- names(drug_maccs_negative)
drug_maccs_negative <- data.frame(matrix(unlist(drug_maccs_negative), nrow=10057, byrow=T))
rownames(drug_maccs_negative) <- drugs

#for correlation estimates
test <- rbind(drug_maccs_positive, drug_maccs_negative)
test_for_corr <- test[,colSums(test) > 0] #there are 7 bits in 166-vector that are all 0
cormat <- round(cor(test_for_corr), 3)
melted_cormat <- melt(cormat)

melted_cormat <- melt(cormat)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())
```

```{r}
#adding variavle Inducer - 1 (if yes), 0 (if not)
drug_maccs_positive$Inducer <- rep("Yes", nrow(drug_maccs_positive))

drug_maccs_negative$Inducer <- rep("No", nrow(drug_maccs_negative))

save(drug_maccs_positive, file = "drug_maccs_positive.Rdata")
save(drug_maccs_negative, file = "drug_maccs_negative.Rdata")
```

Now we can try to perform actual machine learning algorithms for this problem. Note that we have an imbalanced class problem here (10:0.5). Thus we have to take this into account, this [link](https://www.r-bloggers.com/handling-class-imbalance-with-r-and-caret-an-introduction/) was used as a reference. We use class weights to handle class imbalance. 

For all machine learning models use tuneLength = 10!

## Logistic regression

We start with weighted logistic regression:
```{r}
all_data <- rbind(drug_maccs_positive, drug_maccs_negative)
all_data$Inducer <- factor(all_data$Inducer)

prop.table(table(all_data$Inducer)) #0 is not an inducer, 1 is an inducer (of SOX17 expression)
```

Using this [link](http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/) as a reference.
```{r}
#deleting columns with zeros everywhere
x <- all_data$Inducer
all_data <- all_data[,-167]
all_data <- all_data[,colSums(all_data) > 0]
all_data$Inducer <- x

#splitting into train and test sets (using stratified shuffle split to retain class proportions)
train.index <- createDataPartition(all_data$Inducer, p = 0.8, list = FALSE)
train_data <- all_data[train.index,]
test_data <- all_data[-train.index,]

###########################################
#FOR TESTING
#x <- test_data$Inducer
#test_data <- test_data[,-167]
#test_data <- test_data[,colSums(test_data) > 0]
#test_data$Inducer <- x
#rm(x)
#train.index <- createDataPartition(test_data$Inducer, p = 0.8, list = FALSE)
#train_test <- test_data[train.index,]
#test_test <- test_data[-train.index,]
###########################################

# Create model weights (they sum to one) - check in caret documentation!!
model_weights <- ifelse(train_data$Inducer == "No",
                        (1/table(train_data$Inducer)[1])*0.5,
                        (1/table(train_data$Inducer)[2])*0.5)

# Set up control function for training (stratified k-fold with repeats)
ctrl <- trainControl(method = "repeatedcv",
                     number = 5,
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

# Build weighted model (no regularizer) - gives ideal predictions
#weighted_logistic_fit <- train(Inducer ~ .,
#                               data = train_data,
#                               method = "glm",
#                               weights = model_weights,
#                               metric = "ROC",
#                               trControl = ctrl)

# Build model with lasso regularizer (alpha 1 stands for lasso; .5 for elastic net, 0 for ridge regression)
set.seed(1492)

tuneGrid=expand.grid(
              .alpha=1,
              .lambda=seq(0, 2, by = 0.1))


weighted_logistic_fit_lasso <- train(Inducer ~ .,
                                     data = train_data,
                                     method = "glmnet",
                                     weights = model_weights,
                                     family = "binomial",
                                     tuneGrid = tuneGrid,
                                     tuneLength=5,
                                     metric = "ROC",
                                     trControl = ctrl)
save(weighted_logistic_fit_lasso, file="weighted_logistic_fit_lasso.Rdata")
# Build model with elastic regularizer (alpha 1 stands for lasso; .5 for elastic net, 0 for ridge regression)
set.seed(1492)

tuneGrid=expand.grid(
              .alpha=0.5,
              .lambda=seq(0, 2, by = 0.1))


weighted_logistic_fit_elastic <- train(Inducer ~ .,
                                     data = train_data,
                                     method = "glmnet",
                                     weights = model_weights,
                                     family = "binomial",
                                     tuneGrid = tuneGrid,
                                     tuneLength=5,
                                     metric = "ROC",
                                     trControl = ctrl)

save(weighted_logistic_fit_elastic, file="weighted_logistic_fit_elastic.Rdata")
# Build model with ridge regularizer (alpha 1 stands for lasso; .5 for elastic net, 0 for ridge regression)
set.seed(1492)

tuneGrid=expand.grid(
              .alpha=0,
              .lambda=seq(0, 10, by = 0.1))


weighted_logistic_fit_ridge <- train(Inducer ~ .,
                                     data = train_data,
                                     method = "glmnet",
                                     weights = model_weights,
                                     family = "binomial",
                                     tuneGrid = tuneGrid,
                                     tuneLength=5,
                                     metric = "ROC",
                                     trControl = ctrl)

save(weighted_logistic_fit_ridge, file="weighted_logistic_fit_ridge.Rdata")
# Build custom AUC function to extract AUC
# from the caret model object
test_roc <- function(model, data) {
  
  pROC::roc(data$Inducer,
      predict(model, data, type = "prob")[, "Yes"])

}

model_list <- list(lasso = weighted_logistic_fit_lasso,
                   elastic = weighted_logistic_fit_elastic,
                   ridge = weighted_logistic_fit_ridge)


model_list_roc <- model_list %>%
  map(test_roc, data = test_data)

model_list_roc %>%
  map(pROC::auc)

#weighted_logistic_fit_lasso %>%
#  test_roc(data = test_data) %>%
#  pROC::auc()
```
```{r}
rValues <- resamples(model_list)
bwplot(rValues, metric="ROC")
```

## K nearest neighbors

Try to follow this [link](https://www.r-bloggers.com/k-nearest-neighbor-step-by-step-tutorial/) for now.
```{r}
#it takes 15 minutes to run, be careful (for tuneLength = 3 - k=5,7,9; for k=9 ROC is 0.77 with 0.99 sens, but 0.012 specific)
#running with expand.grid(k = seq(8,20,by=2)) takes half an hour (31 min)
set.seed(1492)

start.time <- Sys.time()

tuneGrid <- expand.grid(k = seq(8,26,by=2))

knn_model_fit <- train(Inducer ~ .,
                       data = train_data,
                       method = "knn",
                       #weights = model_weights,
                       #family = "binomial",
                       metric = "ROC",
                       tuneGrid = tuneGrid, 
                       #tuneLength=10,
                       trControl = ctrl)

save(knn_model_fit, file="knn_model_fit.Rdata")

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```
```{r}
knn_model_fit$results
```


```{r}
plot(knn_model_fit)
```
```{r}
valid_pred <- predict(knn_model_fit, test_data, type = "prob")

pred_val <-prediction(valid_pred[,2], test_data$Inducer)

#perf_val <- performance(pred_val, "auc") #0.81

perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 2.5)
```
```{r}
knn_model_fit %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```
```{r}
rValues <- resamples(list(ridge = weighted_logistic_fit_ridge,
                          knn = knn_model_fit))
bwplot(rValues, metric="ROC")
```


## Support Vector Machines

(Try Gaussian kernel - radial basis function)
We receive 'Cannot scale data' because some of the columns are all zeros, and that is why we don't do pre-processing: preProcess default - no pre-processing.  
```{r}
set.seed(1492)
#takes 5 minutres
start.time <- Sys.time()

#tuneGrid <- expand.grid(C = seq(0.1,10,by=0.1))

svm_Linear <- train(Inducer ~., 
                    data = train_data, 
                    method = "svmLinear",
                    trControl=ctrl,
                    #tuneLength = 9,
                    metric = "ROC", scale=FALSE)

save(svm_Linear, file="svm_Linear.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```
```{r}
svm_Linear %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```
```{r}
valid_pred <- predict(svm_Linear, test_data, type = "prob")

pred_val <-prediction(valid_pred[,2], test_data$Inducer)

#perf_val <- performance(pred_val, "auc") #0.81

perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 2.5)
```
```{r}

rValues <- resamples(list(ridge = weighted_logistic_fit_ridge,
                          knn = knn_model_fit,
                          svm_linear = svm_Linear))
bwplot(rValues, metric="ROC")
```

```{r}
#with Gausian kernel
#runs almost 3 hours!!!
set.seed(1492)
start.time <- Sys.time()

svm_Gaussian <- train(Inducer ~., 
                    data = train_data, 
                    method = "svmRadial",
                    trControl=ctrl,
                    metric = "ROC",
                    #tuneGrid = tuneGrid,
                    tuneLength = 10,
                    scale = FALSE)

save(svm_Gaussian, file="svm_Gaussian.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

```

```{r}
svm_Gaussian
```

```{r}
svm_Gaussian %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```
```{r}
valid_pred <- predict(svm_Gaussian, test_data, type = "prob")

pred_val <-prediction(valid_pred[,2], test_data$Inducer)

#perf_val <- performance(pred_val, "auc") #0.81

perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 2.5)
```
```{r}
rValues <- resamples(list(ridge = weighted_logistic_fit_ridge,
                          knn = knn_model_fit,
                          svm_linear = svm_Linear,
                          svm_gaussian = svm_Gaussian))
bwplot(rValues, metric="ROC")
```

## Random Forest

Just classic random forest:
```{r}
set.seed(1492)
#it takes 1 hour to run
start.time <- Sys.time()

#tuneGrid <- expand.grid(C = seq(0.1,10,by=0.1))

rf_fit <- train(Inducer ~., 
                    data = train_data, 
                    method = "rf",
                    trControl=ctrl,
                    #weights = model_weights,
                    tuneLength = 10,
                    metric = "ROC",
                    allowParallel=TRUE)

save(rf_fit, file="rf_fit.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```
```{r}
rf_fit %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```
```{r}
#mtry (#Randomly Selected Predictors)
rf_fit$results
```
```{r}
valid_pred <- predict(rf_fit, test_data, type = "prob")

pred_val <-prediction(valid_pred[,2], test_data$Inducer)

#perf_val <- performance(pred_val, "auc") #0.81

perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 2.5)
```
```{r}
rValues <- resamples(list(ridge = weighted_logistic_fit_ridge,
                          knn = knn_model_fit,
                          svm_linear = svm_Linear,
                          svm_gaussian = svm_Gaussian,
                          rf = rf_fit))
bwplot(rValues, metric="ROC")
```

Random forest with weights:
```{r}
set.seed(1492)
#takes 33 minutes to run!
start.time <- Sys.time()

#tuneGrid <- expand.grid(C = seq(0.1,10,by=0.1))

rf_weighted_fit <- train(Inducer ~., 
                    data = train_data, 
                    method = "ranger",
                    trControl=ctrl,
                    tuneLength = 5,
                    weights = model_weights,
                    metric = "ROC")

save(rf_weighted_fit, file="rf_weighted_fit.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```
```{r}
rf_weighted_fit %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```
```{r}
#mtry (#Randomly Selected Predictors)
rf_weighted_fit$results
```
```{r}
valid_pred <- predict(rf_weighted_fit, test_data, type = "prob")

pred_val <-prediction(valid_pred[,2], test_data$Inducer)

#perf_val <- performance(pred_val, "auc") #0.81

perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 2.5)
```


## Stochastic Gradient boosting

```{r}
set.seed(1492)
#takes two hours to run!
start.time <- Sys.time()

#tuneGrid <- expand.grid(C = seq(0.1,10,by=0.1))

gbm_fit <- train(Inducer ~., 
                    data = train_data, 
                    method = "gbm",
                    trControl=ctrl,
                    weights = model_weights,
                    metric = "ROC",
                    tuneLength = 5, verbose = FALSE)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

save(gbm_fit, file="gbm_fit.Rdata")
```

```{r}
gbm_fit %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```
```{r}

valid_pred <- predict(gbm_fit, test_data, type = "prob")

pred_val <-prediction(valid_pred[,2], test_data$Inducer)

#perf_val <- performance(pred_val, "auc") #0.81

perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 2.5)
```
```{r}
rValues <- resamples(list(ridge = weighted_logistic_fit_ridge,
                          knn = knn_model_fit,
                          svm_linear = svm_Linear,
                          svm_gaussian = svm_Gaussian,
                          rf = rf_fit,
                          rf_weighted = rf_weighted_fit,
                          boosting = gbm_fit))
bwplot(rValues, metric = "ROC")

```

# REFINING

We will refine logistic regression with ridge and stochastic gradient boosting to see if we can increase the performance.

## Logistic regression with ridge

```{r}
weighted_logistic_fit_ridge
```
The optimal lambda is 0.1. Let's play around this value a little bit:
```{r}
set.seed(1492)

tuneGrid=expand.grid(
              .alpha=0,
              .lambda=seq(0.05, 0.2, by = 0.01))


weighted_logistic_fit_ridge_tuned <- train(Inducer ~ .,
                                     data = train_data,
                                     method = "glmnet",
                                     weights = model_weights,
                                     family = "binomial",
                                     tuneGrid = tuneGrid,
                                     tuneLength=5,
                                     metric = "ROC",
                                     trControl = ctrl)

weighted_logistic_fit_ridge_tuned
```

it's tiny improvement in ~0.0001
```{r}
weighted_logistic_fit_ridge_tuned %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```

## Gradient boosting

Now let's focus on improving stochastic gradient boosting (gbm):
```{r}
gbm_fit
```

Let's tune this a little bit:
```{r}
set.seed(1492)
#takes two hours to run!
start.time <- Sys.time()

#tuneGrid <- expand.grid(C = seq(0.1,10,by=0.1))
tuneGrid <- expand.grid(n.trees = seq(40,100,by=10),
                        interaction.depth = c(3,4,5),
                        shrinkage = 0.1,
                        n.minobsinnode = 10)

gbm_fit_tuned <- train(Inducer ~., 
                    data = train_data, 
                    method = "gbm",
                    trControl=ctrl,
                    weights = model_weights,
                    metric = "ROC",
                    tuneGrid = tuneGrid,
                    #tuneLength = 5, 
                    verbose = FALSE)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

```
```{r}
gbm_fit_tuned
```
```{r}
gbm_fit_tuned %>%
  test_roc(data = test_data) %>%
  pROC::auc()
```

# Accuracy metric

Since improvement is not so big, we will focus on three best methods so far: logistic regression with ridge, stochastic gradient boosting, random forest. And check the accuracy metric:

## Logistic regression with ridge

```{r}
set.seed(1492)

tuneGrid=expand.grid(
              .alpha=0,
              .lambda=0.1) #the optimal

ctrl <- trainControl(method = "repeatedcv",
                     number = 5,
                     repeats = 5)

weighted_logistic_fit_ridge_accuracy <- train(Inducer ~ .,
                                     data = train_data,
                                     method = "glmnet",
                                     weights = model_weights,
                                     family = "binomial",
                                     tuneGrid = tuneGrid,
                                     tuneLength=5,
                                     metric = "Accuracy",
                                     trControl = ctrl)

save(weighted_logistic_fit_ridge_accuracy, file="weighted_logistic_fit_ridge_accuracy.Rdata")

weighted_logistic_fit_ridge_accuracy
```
```{r}
# make predictions
x_test <- test_data[,1:159]
y_test <- test_data$Inducer
predictions <- predict(weighted_logistic_fit_ridge_accuracy, x_test)
# summarize results
confusionMatrix(predictions, y_test)
```
Accuracy is 0.752
```{r}
accuracy <- table(predictions, y_test)
sum(diag(accuracy))/sum(accuracy)
```

## Random forest

```{r}
set.seed(1492)
#takes 33 minutes to run!
start.time <- Sys.time()

tuneGrid=expand.grid(
              mtry=2,
              splitrule='extratrees',
              min.node.size=1) #the optimal


rf_weighted_fit_accuracy <- train(Inducer ~., 
                    data = train_data, 
                    method = "ranger",
                    trControl=ctrl,
                    tuneGrid = tuneGrid,
                    weights = model_weights,
                    metric = "Accuracy")

save(rf_weighted_fit_accuracy, file="rf_weighted_fit_accuracy.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

rf_weighted_fit_accuracy
```
```{r}
# make predictions
x_test <- test_data[,1:159]
y_test <- test_data$Inducer
predictions <- predict(rf_weighted_fit_accuracy, x_test)
# summarize results
confusionMatrix(predictions, y_test)
```

## Stochastic gradient boosting

```{r}
set.seed(1492)
#takes two hours to run!
start.time <- Sys.time()

tuneGrid <- expand.grid(n.trees = 50,
                        interaction.depth = 4,
                        shrinkage = 0.1,
                        n.minobsinnode = 10)

gbm_fit_accuracy <- train(Inducer ~., 
                    data = train_data, 
                    method = "gbm",
                    trControl=ctrl,
                    weights = model_weights,
                    metric = "Accuracy",
                    tuneGrid = tuneGrid, 
                    verbose = FALSE)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

save(gbm_fit_accuracy, file="gbm_fit_accuracy.Rdata")
gbm_fit_accuracy
```
```{r}
# make predictions
x_test <- test_data[,1:159]
y_test <- test_data$Inducer
predictions <- predict(gbm_fit_accuracy, x_test)
# summarize results
confusionMatrix(predictions, y_test)
```
```{r}
rValues <- resamples(list(ridge = weighted_logistic_fit_ridge_accuracy,
                          rf_weighted = rf_weighted_fit_accuracy,
                          boosting = gbm_fit_accuracy))
bwplot(rValues, metric="Accuracy")
```

Let's calculate accuracy for other classifiers (knn, svm) to show their accuracy

## KNN

```{r}
set.seed(1492)

start.time <- Sys.time()

tuneGrid <- expand.grid(k = 26)

knn_model_fit_accuracy <- train(Inducer ~ .,
                       data = train_data,
                       method = "knn",
                       #weights = model_weights,
                       #family = "binomial",
                       metric = "Accuracy",
                       tuneGrid = tuneGrid, 
                       #tuneLength=10,
                       trControl = ctrl)

save(knn_model_fit_accuracy, file="knn_model_fit_accuracy.Rdata")

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

knn_model_fit_accuracy
```
```{r}
# make predictions
x_test <- test_data[,1:159]
y_test <- test_data$Inducer
predictions <- predict(knn_model_fit_accuracy, x_test)
# summarize results
confusionMatrix(predictions, y_test)
```

## SVM linear

```{r}
set.seed(1492)
#takes 5 minutres
start.time <- Sys.time()

tuneGrid <- expand.grid(C = 1)

svm_Linear_accuracy <- train(Inducer ~., 
                    data = train_data, 
                    method = "svmLinear",
                    trControl=ctrl,
                    #tuneLength = 9,
                    metric = "Accuracy", 
                    scale=FALSE)

save(svm_Linear_accuracy, file="svm_Linear_accuracy.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

svm_Linear_accuracy
```
```{r}
# make predictions
x_test <- test_data[,1:159]
y_test <- test_data$Inducer
predictions <- predict(svm_Linear_accuracy, x_test)
# summarize results
confusionMatrix(predictions, y_test)
```

## SVM Gaussian 

```{r}
#with Gausian kernel
#runs almost 3 hours!!!
set.seed(1492)
start.time <- Sys.time()

tuneGrid <- expand.grid(sigma = 0.0045,
                        C = 128)

svm_Gaussian_accuracy <- train(Inducer ~., 
                    data = train_data, 
                    method = "svmRadial",
                    trControl=ctrl,
                    metric = "Accuracy",
                    tuneGrid = tuneGrid,
                    #tuneLength = 10,
                    scale = FALSE)

save(svm_Gaussian_accuracy, file="svm_Gaussian_accuracy.Rdata")
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

svm_Gaussian_accuracy
```
```{r}
# make predictions
x_test <- test_data[,1:159]
y_test <- test_data$Inducer
predictions <- predict(svm_Gaussian_accuracy, x_test)
# summarize results
confusionMatrix(predictions, y_test)
```